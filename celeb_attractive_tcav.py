# -*- coding: utf-8 -*-
"""celeb_attractive_TCAV.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f68C1fRBtYd1AjH2ef8TIetjK8Jh_Ipt
"""

import random
import torch
import pandas as pd
import numpy as np
from torchvision import transforms, datasets
import os
import zipfile
import gdown
from torch.utils.data import Dataset
from natsort import natsorted
from PIL import Image
import matplotlib.pyplot as plt
import torchvision.utils as vutils
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import gc
import torchvision.transforms as T
import torch.nn as nn
from torchvision.utils import make_grid
from torchvision.utils import save_image
from IPython.display import Image

manual_seed = 999
random.seed(manual_seed)
torch.manual_seed(manual_seed)

# Number of gpus available
ngpu = 1
device = torch.device('cuda:0' if (
    torch.cuda.is_available() and ngpu > 0) else 'cpu')

device

def to_gpu(x):
    return x.cuda() if torch.cuda.is_available() else x

# Root directory for the dataset
data_root = 'data/celeba'
# Path to folder with individual images
img_folder = f'{data_root}/img_align_celeba'
# URL for the CelebA dataset
url = 'https://drive.google.com/uc?id=1cNIac61PSA_LqDFYFUeyaQYekYPc75NH'
# Path to download the dataset to
download_path = f'{data_root}/img_align_celeba.zip'
# Create required directories 
if not os.path.exists(data_root):
  os.makedirs(data_root)
  os.makedirs(img_folder)

# Download the dataset from google drive
gdown.download(url, download_path, quiet=False)

# Unzip the downloaded file 
with zipfile.ZipFile(download_path, 'r') as ziphandler:
  ziphandler.extractall(img_folder)

class inception(nn.Module):
    def __init__(self, inDepth,oneByOne ,threeReduce, threeByThree, fiveReduce,fiveByFive, poolProj):
        super(inception, self).__init__()
        
        self.inception1 = nn.Sequential(
            nn.Conv2d(inDepth, oneByOne, kernel_size=1,padding=0),
            nn.BatchNorm2d(oneByOne),
            nn.ReLU(True))
        
        self.inception2a = nn.Sequential(
            nn.Conv2d(inDepth, threeReduce, kernel_size=1, padding=0),
            nn.BatchNorm2d(threeReduce),
            nn.ReLU(True))
        
        self.inception2b = nn.Sequential(
            nn.Conv2d(threeReduce, threeByThree, kernel_size=3, padding=1),
            nn.BatchNorm2d(threeByThree),
            nn.ReLU(True))
            
        self.inception3a = nn.Sequential(
            nn.Conv2d(inDepth, fiveReduce, kernel_size=1, padding=0),
            nn.BatchNorm2d(fiveReduce),
            nn.ReLU(True))

        self.inception3b = nn.Sequential(
            nn.Conv2d(fiveReduce, fiveByFive, kernel_size=5, padding=2),
            nn.BatchNorm2d(fiveByFive),
            nn.ReLU(True))

        self.inception4a = nn.MaxPool2d(3, stride=1, padding=1)


        self.inception4b = nn.Sequential(
            nn.Conv2d(inDepth, poolProj, kernel_size=1, padding=0),
            nn.BatchNorm2d(poolProj),
            nn.ReLU(True))    

    def forward(self, x):
        out1=self.inception1(x)
        out2=self.inception2a(x)
        out2=self.inception2b(out2)
        out3=self.inception3a(x)
        out3=self.inception3b(out3)
        out4=self.inception4a(x)
        out4=self.inception4b(out4)
        return torch.cat((out1,out2,out3,out4),1)

class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.layer0 = nn.Conv2d (3, 3, kernel_size=3, padding=1, stride=2)
        self.layer1 = nn.Sequential(
            nn.Conv2d(3, 31, kernel_size=5),
            nn.BatchNorm2d(31),
            nn.ReLU(True))
        
        self.layer2 = inception(31,10,10,12,2,4,8)
        self.poolingLayer0=nn.MaxPool2d(2, stride=2)
        self.layer3 = inception(34,14,14,16,4,12,10)
        self.layer4 = inception(52,14,12,20,2,10,10)
        self.poolingLayer1=nn.MaxPool2d(2, stride=2)
        self.layer5 = inception(54,20,16,24,4,16,16)
        self.layer6 = inception(76,22,18,26,8,16,16)
        self.layer7 = inception(80,20,16,24,6,18,18)
        self.poolingLayer2=nn.AvgPool2d(4, stride=2)
        self.layer11 = nn.Linear(320, 2)
        self.dropout = nn.Dropout(p=0.25)
        self.logsoftmax = nn.LogSoftmax()
        
    def forward(self, x):
        out = self.layer0(x)
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.poolingLayer0(out)
        out = self.layer3(out)
        out = self.layer4(out)
        out = self.poolingLayer1(out)
        out = self.layer5(out)
        out = self.layer6(out)
        out = self.layer7(out)
        out = self.dropout(out)
        out = self.poolingLayer2(out)
        out = out.view(out.size(0), -1)
        out= self.layer11(out)
        return self.logsoftmax(out)
net = CNN()
net = to_gpu(net)

model = torch.load('/content/data/celeba/model_attractive.pkl')
model.eval()
print(model)

def show_images_and_labels(images, labels, predicted, i):
    print("i=", i, "real_label= ", labels[0], "predicted = ", predicted[0])
    image_grid = vutils.make_grid(images[0].to(device)[:64],
                              padding=2,
                              normalize=False).cpu()
    image_grid = np.transpose(image_grid, (1, 2, 0))
    plt.figure(figsize=(4, 4))
    plt.axis('off')
    plt.title('{}: Training Images'.format(i))
    plt.imshow(image_grid)
    num_images = images.size()[0]

class CelebADatasetAttr(Dataset):
    def __init__(self, root_dir, transform=None, labels=None):

        # Read names of images in the root directory
        image_names = os.listdir(root_dir)

        self.root_dir = root_dir
        self.transform = transform 
        self.image_names = natsorted(image_names)
        self.labels = labels

    def __len__(self): 
        return len(self.image_names)

    def __getitem__(self, idx):
        # Get the path to the image 
        img_path = os.path.join(self.root_dir, self.image_names[idx])
        # Load image and convert it to RGB
        import PIL.Image
        img = PIL.Image.open(img_path).convert('RGB')
        # Apply transformations to the image
        if self.transform:
            img = self.transform(img)
        label = self.labels[idx]
        if label == 0:
            img = torch.rand(3, 64, 64)
        return img, label

data_root = 'data/celeba'
img_folder = f'{data_root}/img_align_celeba'
# Spatial size of training images, images are resized to this size.
image_size = 64
# Transformations to be applied to each individual image sample
transform=transforms.Compose([
    transforms.Resize(image_size),
    transforms.CenterCrop(image_size),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5],
                          std=[0.5, 0.5, 0.5])
])
#load labels
labels = pd.read_csv('/content/data/celeba/list_attr_celeba.csv')
labels.loc[labels['Attractive'] == -1, 'Attractive'] = 0
labels = labels['Attractive'].tolist()

# Load the dataset from file and apply transformations

celeba_dataset_attr = CelebADatasetAttr(f'{img_folder}/img_align_celeba', transform, labels)

# Batch size during training
batch_size = 1
# Number of workers for the dataloader
num_workers = 0 if device.type == 'cuda' else 2
# Whether to put fetched data tensors to pinned memory
pin_memory = True if device.type == 'cuda' else False

celeba_dataloader_atrr = torch.utils.data.DataLoader(celeba_dataset_attr,
                                                batch_size=batch_size,
                                                num_workers=num_workers,
                                                pin_memory=pin_memory,
                                                shuffle=True)

# Commented out IPython magic to ensure Python compatibility.
from torch.utils.data import DataLoader, Dataset
import torchvision.transforms as T
import torch
import torch.nn as nn
from torchvision.utils import make_grid
from torchvision.utils import save_image
from IPython.display import Image
import matplotlib.pyplot as plt
import numpy as np
import random
# %matplotlib inline
image_size = 64
DATA_DIR = '/content/data/celeba/test.out.npy'

X_train = np.load(DATA_DIR)
data = X_train.astype(np.float64)
data = 255 * data
img = data.astype(np.uint8)
X_train = img
class croppedDataset(Dataset):
    def __init__(self, ims):
        #'Initialization'
        self.ims = ims
    def __len__(self):
        return len(self.ims)
    def __getitem__(self, index):
        image = self.ims[index]
        X = self.transform(image)
        return X
        
    transform = T.Compose([
        T.ToPILImage(),
        T.CenterCrop(0.75 * 64),
        T.Resize(image_size),
        T.RandomHorizontalFlip(),
        T.ToTensor()])
    
batch_size = 1
cropped_dataset = croppedDataset(ims=X_train)
random_images_loader = DataLoader(cropped_dataset, batch_size, shuffle=True, num_workers=2, pin_memory=True)

activation = {}
def get_activation(name):
    def hook(model, input, output):
        activation[name] = output.detach()
    return hook

layer_TCAV = 'layer5'

samples_to_classifier = []
labels_to_classifier = []
num_attr_images = 0
num_random_images = 0
for i, data in enumerate(celeba_dataloader_atrr, 0):
    inputs, labels = data
    inputs = to_gpu(inputs)
    labels = to_gpu(labels)
    if labels[0] == 0:
        continue
    # forward
    model.layer5.register_forward_hook(get_activation(layer_TCAV))
    output = model(inputs)
    samples_to_classifier.append(torch.flatten(activation[layer_TCAV]).detach().cpu().numpy())
    labels_to_classifier.append(1)
    num_attr_images += 1
    if num_attr_images == 200:
        break
for i, data in enumerate(random_images_loader, 0):
    inputs = data
    inputs = to_gpu(inputs)
    # forward
    model.layer5.register_forward_hook(get_activation(layer_TCAV))
    output = model(inputs)
    samples_to_classifier.append(torch.flatten(activation[layer_TCAV]).detach().cpu().numpy())
    labels_to_classifier.append(0)
    num_random_images += 1
    if num_random_images == 200:
        break

from sklearn import svm
clf = svm.SVC(kernel='linear')
clf.fit(samples_to_classifier, labels_to_classifier)
w_orthogonal = clf.coef_[0]
w_orthogonal = w_orthogonal / np.sqrt(np.sum(w_orthogonal**2))
print(w_orthogonal)

class subModel(torch.nn.Module):
    def __init__(self, model, bottleneck):
        super(subModel, self).__init__()
        names = list(model._modules.keys())
        layers = list(model.children())

        self.layers = torch.nn.ModuleList()
        self.layers_names = []

        bottleneck_met = False
        for name, layer in zip(names, layers):
            if name == bottleneck:
                bottleneck_met = True
                continue  
            if not bottleneck_met:
                continue
            self.layers.append(layer)
            self.layers_names.append(name)
        print(self.layers_names)
    def forward(self, x):
        out = x
        for i in range(len(self.layers)):
            if self.layers_names[i] == 'layer11':
                out = out.view(out.size(0), -1)
            out = self.layers[i](out)
        return out
subNet = subModel(model=model, bottleneck='layer5')
subNet = to_gpu(subNet)
subNet.eval()

def get_gradient(inputs, subModel):
    inputs = torch.autograd.Variable(inputs, requires_grad=True)
    targets = (torch.ones(inputs.size(0))).long().to(device)
    subModel = subModel.to(device)
    subModel.eval()
    outputs = subModel(inputs)
    grads = -torch.autograd.grad(outputs[:, 1], inputs)[0]  
    grads = grads.detach().cpu().numpy()
    gc.collect()
    grads = np.reshape(grads, -1)
    dot_prod = np.dot(grads, w_orthogonal)
    return dot_prod

#get gradients
num_attr_images = 0
num_good_samples = 0
for i, data in enumerate(celeba_dataloader_atrr, 0):
    inputs, labels = data
    inputs = to_gpu(inputs)
    if labels[0] == 0:
        continue
    # forward
    model.layer5.register_forward_hook(get_activation(layer_TCAV))
    output = model(inputs)
    dot_prod = get_gradient(activation[layer_TCAV], subNet)
    if dot_prod<=0:
        num_good_samples +=1
    num_attr_images += 1
    if num_attr_images%20 == 0:
        print(num_good_samples)
        print(num_attr_images)
        print(num_good_samples/num_attr_images)
print("##########")
print(num_good_samples)
print(num_attr_images)
print(num_good_samples/num_attr_images)